{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this notebook from inside keras-retinanet repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Download the VOCdevkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for downloading Dataset\n",
    "\n",
    "%%time\n",
    "#downloads and adds 'tmp' prefix\n",
    "!wget -P /tmp http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
    "!wget -P /tmp http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
    "    \n",
    "#extracts\n",
    " \n",
    "!tar -xvf /tmp/VOCtrainval_06-Nov-2007.tar \n",
    "!tar -xvf /tmp/VOCtest_06-Nov-2007.tar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginning of Training Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model by calling for instance:<br/>\n",
    "Suggested to initialize model on cpu before turning into a multi_gpu model to save gpu memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras_retinanet.models import load_model\n",
    "from keras_retinanet import models\n",
    "#from keras_retinanet.utils.model import freeze #as freeze_model\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "        model = load_model('./snapshots/_pretrained_model.h5', backbone_name='resnet50')\n",
    "        #model = load_model('./snapshots/resnet50_pascal_01.h5', backbone_name='resnet50') #this was my model I previously trained\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empirically, the following compile arguments have been found to work well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras_retinanet import losses\n",
    "import keras\n",
    "\n",
    "model.compile(\n",
    "    loss={\n",
    "        'regression'    : losses.smooth_l1(),\n",
    "        'classification': losses.focal()\n",
    "    },\n",
    "    optimizer=keras.optimizers.adam(lr=1e-5, clipnorm=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize transform_generator, a Retinanet Utils random_transform_generator object that is used to apply data augmentation, randomly translating, rotating, resizing, etc. images on the fly.\n",
    "\n",
    "Performing data augmentation is a form of regularization, enabling our model to generalize better.\n",
    "However, applying data augmentation implies that our training data is no longer “static” — the data is constantly changing.\n",
    "Each new batch of data is randomly adjusted according to the parameters supplied to random_transform_generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras_retinanet.utils.transform import random_transform_generator\n",
    "\n",
    "transform_generator = random_transform_generator(\n",
    "            min_rotation=-0.1,\n",
    "            max_rotation=0.1,\n",
    "            min_translation=(-0.1, -0.1),\n",
    "            max_translation=(0.1, 0.1),\n",
    "            min_shear=-0.1,\n",
    "            max_shear=0.1,\n",
    "            min_scaling=(0.9, 0.9),\n",
    "            max_scaling=(1.1, 1.1),\n",
    "            flip_x_chance=0.5,\n",
    "            flip_y_chance=0.5,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_generator & validation_generator get plugged into .fit_generator to generate data for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras_retinanet.preprocessing.pascal_voc import PascalVocGenerator\n",
    "import argparse\n",
    "import keras.preprocessing.image\n",
    "from keras_retinanet.VOCdevkit import VOC2007\n",
    "\n",
    "\n",
    "train_generator = PascalVocGenerator(\n",
    "           'keras_retinanet/VOCdevkit/VOC2007',\n",
    "            'trainval',\n",
    "            transform_generator=transform_generator,\n",
    "        )\n",
    "\n",
    "validation_generator = PascalVocGenerator(\n",
    "            'keras_retinanet/VOCdevkit/VOC2007',\n",
    "            'test',\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize a Keras **ModelCheckpoint** object, which saves the model after every epoch.\n",
    "* make filepath = weights.{epoch:02d}-{val_loss:.2f}.h to have model checkpoints to be saved with epoch number and validation loss in the filename.\n",
    "* make sure to include **epoch variable in your filepath, otherwise your saved model will be replaced after every epoch.**\n",
    "\n",
    "Arguments:\n",
    "- *filepath*: string, path to save the model file.\n",
    "- *monitor*: quantity to monitor.\n",
    "- *verbose*: verbosity mode. \n",
    "    - 2 will just show \"Epoch 1/20\", 1 will show you an animated progress bar, 0 will show nothing, \n",
    "- *save_best_only*: if save_best_only=True, the latest best model according to the quantity monitored will not be overwritten.\n",
    "- *save_weights_only*: if True, then only the model's weights will be saved (model.save_weights(filepath)), else the full model is saved (model.save(filepath)).\n",
    "- *mode*: one of {auto, min, max}. If save_best_only=True, the decision to overwrite the current save file is made based on either the maximization or the minimization of the monitored quantity. For val_acc, this should be max, for val_loss this should be min, etc. In auto mode, the direction is automatically inferred from the name of the monitored quantity.\n",
    "- *period*: Interval (number of epochs) between checkpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ex: keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "Arguments:\n",
    "\n",
    "- *monitor*: quantity to be monitored.\n",
    "- *min_delta*: minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.\n",
    "- *patience*: number of epochs with no improvement after which training will be stopped.\n",
    "- *verbose*: verbosity mode. \n",
    "    - 2 will just show \"Epoch 1/20\", 1 will show you an animated progress bar, 0 will show nothing, \n",
    "- *mode*: one of {auto, min, max}. In min mode, training will stop when the quantity monitored has stopped decreasing; in max mode it will stop when the quantity monitored has stopped increasing; in auto mode, the direction is automatically inferred from the name of the monitored quantity.\n",
    "- *baseline*: Baseline value for the monitored quantity to reach. Training will stop if the model doesn't show improvement over the baseline.\n",
    "- *restore_best_weights*: whether to restore model weights from the epoch with the best value of the monitored quantity. If False, the model weights obtained at the last step of training are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras_retinanet.callbacks import RedirectModel\n",
    "\n",
    "# Checkpoint: save models that are improvements\n",
    "checkpoint = ModelCheckpoint('myweights1.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', save_best_only=True,save_weights_only=True)\n",
    "checkpoint = RedirectModel(checkpoint, model)\n",
    "\n",
    "#stopping: stops training if val_loss stops improving\n",
    "stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .fit_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to utilize Keras’ .fit_generator  function to train our model.\n",
    "\n",
    "As the name suggests, the .fit_generator  function assumes there is an underlying function that is generating the data for it. The function itself is a Python generator.\n",
    "\n",
    "Internally, Keras is using the following process when training a model with .fit_generator :\n",
    "\n",
    "- Keras calls the generator function supplied to .fit_generator  (in this case, train_generator ).\n",
    "- The generator function yields a batch of size batch_size to the .fit_generator  function.\n",
    "- The .fit_generator  function accepts the batch of data, performs backpropagation, and updates the weights in our \n",
    "   model.\n",
    "- This process is repeated until we have reached the desired number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator, \n",
    "        epochs=10, \n",
    "        callbacks=[checkpoint, stopping],\n",
    "        validation_data = validation_generator,\n",
    "        verbose=1     # 2 will just show \"Epoch 1/20\", 1 will show you an animated progress bar, 0 will show nothing, \n",
    "    ).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using **model.save('filename.h5')** will create a .h5 file that will contain:\n",
    "\n",
    "- the *architecture* of the model, allowing to re-create the model\n",
    "- the *weights* of the model\n",
    "- the *training configuration* (loss, optimizer)\n",
    "- the *state of the optimizer*, allowing to resume training exactly where you left off.\n",
    "\n",
    "You can then use **keras.models.load_model(filepath)** to reinstantiate your model. load_model will also take care of compiling the model using the saved training configuration (unless the model was never compiled in the first place)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mymodel1.h5') # creates a HDF5 file 'my_model.h5'"
   ]
  },
  
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
